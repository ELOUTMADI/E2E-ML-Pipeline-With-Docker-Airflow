About the Project :
ğ—›ğ—²ğ—¿ğ—² ğ—®ğ—¿ğ—² ğ˜ğ—µğ—² ğ˜€ğ˜ğ—²ğ—½ğ˜€ ğ—¼ğ—³ ğ˜ğ—µğ—² ğ—£ğ—¶ğ—½ğ—²ğ—¹ğ—¶ğ—»ğ—² :

â¡ï¸ Get daily batches from external sources and save them for future use.

â¡ï¸ Split the data into train and test sets and save them for reference.

â¡ï¸ Perform k-fold cross-validation training to tune hyperparameters and choose the best set of parameters.

â¡ï¸ Evaluate the performance on the test set.

â¡ï¸ Store experimental results (best parameters, training conditions, test set performance)

â¡ï¸ The best estimator fit for all data (train and test sets). Save the obtained model for future use.


We will implement this pipeline using Apache Airflow, a popular open-source orchestrator that allows for programmatically building, scheduling, and monitoring workflows. We installed it via #dockercompose and configured it to run in our local environment.
